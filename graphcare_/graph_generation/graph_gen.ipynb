{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "condition_mapping_file = \"../../resources/CCSCM.csv\"\n",
    "procedure_mapping_file = \"../../resources/CCSPROC.csv\"\n",
    "drug_file = \"../../resources/ATC.csv\"\n",
    "\n",
    "condition_dict = {}\n",
    "with open(condition_mapping_file, newline='', encoding='utf-8', errors='replace') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        condition_dict[row['code']] = row['name'].lower()\n",
    "\n",
    "procedure_dict = {}\n",
    "with open(procedure_mapping_file, newline='', encoding='utf-8', errors='replace') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        procedure_dict[row['code']] = row['name'].lower()\n",
    "\n",
    "drug_dict = {}\n",
    "with open(drug_file, newline='', encoding='utf-8', errors='replace') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['level'] == '3.0':\n",
    "            drug_dict[row['code']] = row['name'].lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from ChatGPT import ChatGPT\n",
    "from ChatGPT import ChatGPT\n",
    "import json\n",
    "\n",
    "def extract_data_in_brackets(input_string):\n",
    "    pattern = r\"\\[(.*?)\\]\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    return matches\n",
    "\n",
    "def divide_text(long_text, max_len=800):\n",
    "    sub_texts = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(long_text):\n",
    "        end_idx = start_idx + max_len\n",
    "        sub_text = long_text[start_idx:end_idx]\n",
    "        sub_texts.append(sub_text)\n",
    "        start_idx = end_idx\n",
    "    return sub_texts\n",
    "\n",
    "def filter_triples(triples):\n",
    "    chatgpt = ChatGPT()\n",
    "    response = chatgpt.chat(\n",
    "        f\"\"\"\n",
    "            I have a list of triples. I want to select 50 most important triples from the list.\n",
    "            The importance of a triple is based on how you think it will help imrpove healthcare prediction tasks (e.g., drug recommendation, mortality prediction, readmission prediction …).\n",
    "            If you think a triple is important, please keep it. Otherwise, please remove it.\n",
    "            You can also add triples from your background knowledge.\n",
    "            The total size of the updated list should be below 50.\n",
    "\n",
    "            triples: {triples}\n",
    "            updates:\n",
    "        \"\"\"\n",
    "        )\n",
    "    json_string = str(response)\n",
    "    json_data = json.loads(json_string)\n",
    "\n",
    "    filtered_triples = extract_data_in_brackets(json_data['content'])\n",
    "    return filtered_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChatGPT import ChatGPT\n",
    "import json\n",
    "\n",
    "def graph_gen(term: str, mode: str):\n",
    "    if mode == \"condition\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: systemic lupus erythematosus\n",
    "        updates: [[systemic lupus erythematosus, is an, autoimmune condition], [systemic lupus erythematosus, may cause, nephritis], [anti-nuclear antigen, is a test for, systemic lupus erythematosus], [systemic lupus erythematosus, is treated with, steroids], [methylprednisolone, is a, steroid]]\n",
    "        \"\"\"\n",
    "    elif mode == \"procedure\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: endoscopy\n",
    "        updates: [[endoscopy, is a, medical procedure], [endoscopy, used for, diagnosis], [endoscopic biopsy, is a type of, endoscopy], [endoscopic biopsy, can detect, ulcers]]\n",
    "        \"\"\"\n",
    "    elif mode == \"drug\":\n",
    "        example = \\\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        prompt: iobenzamic acid\n",
    "        updates: [[iobenzamic acid, is a, drug], [iobenzamic acid, may have, side effects], [side effects, can include, nausea], [iobenzamic acid, used as, X-ray contrast agent], [iobenzamic acid, formula, C16H13I3N2O3]]\n",
    "        \"\"\"\n",
    "    chatgpt = ChatGPT()\n",
    "    response = chatgpt.chat(\n",
    "        f\"\"\"\n",
    "            Given a prompt (a medical condition/procedure/drug), extrapolate as many relationships as possible of it and provide a list of updates.\n",
    "            The relationships should be helpful for healthcare prediction (e.g., drug recommendation, mortality prediction, readmission prediction …)\n",
    "            Each update should be exactly in format of [ENTITY 1, RELATIONSHIP, ENTITY 2]. The relationship is directed, so the order matters.\n",
    "            Both ENTITY 1 and ENTITY 2 should be noun.\n",
    "            Any element in [ENTITY 1, RELATIONSHIP, ENTITY 2] should be conclusive, make it as short as possible.\n",
    "            Do this in both breadth and depth. Expand [ENTITY 1, RELATIONSHIP, ENTITY 2] until the size reaches 100.\n",
    "\n",
    "            {example}\n",
    "\n",
    "            prompt: {term}\n",
    "            updates:\n",
    "        \"\"\"\n",
    "        )\n",
    "    json_string = str(response)\n",
    "    json_data = json.loads(json_string)\n",
    "\n",
    "    triples = extract_data_in_brackets(json_data['content'])\n",
    "    outstr = \"\"\n",
    "    for triple in triples:\n",
    "        outstr += triple.replace('[', '').replace(']', '').replace(', ', '\\t') + '\\n'\n",
    "\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Future work - Including Clinical Notes\n",
    "# import json\n",
    "\n",
    "# with open('../../clinical_notes/subject_text_dict.json', 'r') as f:\n",
    "#     subject_text_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# adjust depending on how heavy graph_gen is / API rate limits\n",
    "MAX_WORKERS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/285 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def process_condition(key: str):\n",
    "    \"\"\"Process a single condition key: read existing file, maybe call graph_gen, write back.\"\"\"\n",
    "    file_path = f'../../graphs/condition/CCSCM/{key}.txt'\n",
    "    term = condition_dict[key]\n",
    "\n",
    "    # Case 1: file already exists\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            prev_triples = f.read()\n",
    "\n",
    "        # Only extend if less than 100 lines\n",
    "        if len(prev_triples.splitlines()) < 100:\n",
    "            outstr = graph_gen(term=term, mode=\"condition\")\n",
    "            outstr = prev_triples + outstr\n",
    "            with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(outstr)\n",
    "\n",
    "    # Case 2: file does not exist\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        outstr = graph_gen(term=term, mode=\"condition\")\n",
    "        with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(outstr)\n",
    "\n",
    "    return key  # just to have something to mark completion\n",
    "\n",
    "\n",
    "keys = list(condition_dict.keys())\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(process_condition, key) for key in keys]\n",
    "    for _ in tqdm(as_completed(futures), total=len(futures)):\n",
    "        # nothing to do here, tqdm is just tracking completion\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_drug(key: str):\n",
    "    \"\"\"Process a single drug key: read existing file, maybe call graph_gen, write back.\"\"\"\n",
    "    file_path = f'../../graphs/drug/ATC5/{key}.txt'\n",
    "    term = drug_dict[key]\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            prev_triples = f.read()\n",
    "\n",
    "        # Only extend if less than 150 lines\n",
    "        if len(prev_triples.splitlines()) < 150:\n",
    "            outstr = graph_gen(term=term, mode=\"drug\")\n",
    "            outstr = prev_triples + outstr\n",
    "            with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(outstr)\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        outstr = graph_gen(term=term, mode=\"drug\")\n",
    "        with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(outstr)\n",
    "\n",
    "    return key  # for completion tracking\n",
    "\n",
    "\n",
    "drug_keys = list(drug_dict.keys())\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(process_drug, key) for key in drug_keys]\n",
    "    for _ in tqdm(as_completed(futures), total=len(futures)):\n",
    "        # Just to drive tqdm; nothing else needed here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_drug(key: str):\n",
    "    \"\"\"Handle one drug entry: read file, maybe call graph_gen, write back.\"\"\"\n",
    "    file_path = f'../../graphs/drug/ATC5/{key}.txt'\n",
    "    term = drug_dict[key]\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        # read existing content\n",
    "        with open(file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            prev_triples = f.read()\n",
    "\n",
    "        # only extend if <150 lines\n",
    "        if len(prev_triples.splitlines()) < 150:\n",
    "            outstr = graph_gen(term=term, mode=\"drug\")\n",
    "            outstr = prev_triples + outstr\n",
    "            with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(outstr)\n",
    "\n",
    "    else:\n",
    "        # create directory if needed, then write new content\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        outstr = graph_gen(term=term, mode=\"drug\")\n",
    "        with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(outstr)\n",
    "\n",
    "    return key  # just for completion tracking\n",
    "\n",
    "\n",
    "drug_keys = list(drug_dict.keys())\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(process_drug, key) for key in drug_keys]\n",
    "    for _ in tqdm(as_completed(futures), total=len(futures)):\n",
    "        # tqdm tracks completion, no extra work needed here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_drug_atc3(key: str):\n",
    "    \"\"\"Process a single drug key for ATC3: read existing file, maybe call graph_gen, write back.\"\"\"\n",
    "    file_path = f'../../graphs/drug/ATC3/{key}.txt'\n",
    "    term = drug_dict[key]\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        # Read existing triples\n",
    "        with open(file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            prev_triples = f.read()\n",
    "\n",
    "        # Only extend if less than 150 lines\n",
    "        if len(prev_triples.splitlines()) < 150:\n",
    "            outstr = graph_gen(term=term, mode=\"drug\")\n",
    "            outstr = prev_triples + outstr\n",
    "            with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(outstr)\n",
    "    else:\n",
    "        # Create directory if needed and write new content\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        outstr = graph_gen(term=term, mode=\"drug\")\n",
    "        with open(file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(outstr)\n",
    "\n",
    "    return key  # for completion tracking\n",
    "\n",
    "\n",
    "drug_keys = list(drug_dict.keys())\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(process_drug_atc3, key) for key in drug_keys]\n",
    "    for _ in tqdm(as_completed(futures), total=len(futures)):\n",
    "        # tqdm just tracks completion\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
